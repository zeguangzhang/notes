# 遇到的问题

1 pycharm单行输出长度限制
 print()函数打印过长字符串（我的数据是3.5mb）时，pycharm会把前半部分截掉，只显示后半部分，当时以为是print对字符串长度的限制，于是换了logger日志打印，结果一样。
但是我还想看该字符串内容，怎么办呢，一想，直接打印到文件吧，然后ok，完成看到字符串。当时打印到文件的代码希望你能熟练编写
target_file = '/Users/zzg/Desktop/work/wangyi.txt'
    with open(target_file, 'wt') as f: #wt代表覆盖，at代表追加，没有文件都会自动建立文件
        f.write(fetch_utils.redis_cli.get('yiqing_wangyi_analyse_info'))

2 爬取疫情数据我直接当后端好，还是只是数据由我提供，接口调用服务后端去做？
 这个问题从以前工作经验来讲，应该爬虫来做，觉得加上了一层后端着实没有必要。因为我每次需要10分钟抓一次数据，每次抓取的数据聚合成一个json数据，
 丢进redis的一个key中。如果后端接入，做的只是做一层接口调用服务，取我的redis里面的key的value给前端就行了，而且轮训任务都是前端每10分钟触发一次。
 这样看来是不是后端真的没有必要呢？其实我稍微思索了下，觉得这样也很ok，因为万一并发量很高，对服务造成的压力或者产生的问题不用自己去关心，还有就是
 他们还可以对数据进行深加工，做一些统计分析之类的，也很好，这也是在给程序解耦啊


3 如何划定爬虫与后端界限
爬虫其实就是把爬取的数据规整化就非常ok了。至于你想怎么用是你的问题
后端应该根据业务对原始数据加工成想要的模样，
我为什么要写这个问题，因为单位还是有喜欢懒得写代码的老油条，总是想把活扔给别人，自己去学习或者干点提升自己的事情，在中国很常见，
可以说到处都是，自己比较自律可能人家都觉得你有病。其实我一个后端开发也跟我说爬虫数据我还得统计一些他想要的内容，当时心里有点不高兴，我又不是刚工作的小孩子，
说推给我就推给我，明显是你的业务数据需求啊，你自己想法变换就行啊，你让我变换还不是一个道理吗，我电话当面跟他表达了不情愿，但是说是我们老大说让在我原始数据上统计，
由于没有会议一起讨论过，我只能忍一忍做了，真心有点烧脑，花了大半天做成上线状态了。自己太过于主动和热情，太踏实肯干觉得在北京这座城市很吃亏。


4 python 项目运行完成后日志文件不见了？
这不应该啊，后来问了我媳妇，我媳妇说我刚才看见你那个日志文件我就删了，以为不删你也要删呢。然后我想你删了后打印日志不会重新创建日志文件吗，
经过进一步测试，发现就是不会重新创建日志

5 python 在循环字典时，报错：ValueError: too many values to unpack (expected 2)
 错误姿势： for key, value in class_attrs:
 正确姿势 ：for key, value in class_attrs.items():

 原因是字典这个是一个迭代器对象，参考官方文档找到下列说明，字典只支持Key的遍历,，如果想对key，value，则可以使用items方法。
The “implicit” iteration that dictionaries support only iterates over keys.

6 json.loads()后的json放入json.cn中怎么突然识别不了了，要用json.dumps(data)传递给json.cn中，好心办坏事

7 python 重启问题

8 404 res.text返回页面内容吗,这个网站服务端也可以自定义，返回一些内容然后返回404状态码，访问网易疫情时，个别城市下架就会返回这个

9 我们搞后台项目，报错有个东西权限不够，一看同事给我传过来的文件本地权限跟同事不一样，所以主动修改了权限就ok了。 这是因为文件在复制或者远程传输中文件的权限会改变，可以了解下cp命令如何保证权限属性不变的
